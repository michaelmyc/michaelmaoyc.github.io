<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>deep-learning on Michael Mao</title><link>https://michaelmao.me/tags/deep-learning/</link><description>Recent content in deep-learning on Michael Mao</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 01 Oct 2023 23:30:46 +0800</lastBuildDate><atom:link href="https://michaelmao.me/tags/deep-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Building Blocks of Neural Networks</title><link>https://michaelmao.me/blog/building-blocks-of-neural-networks/</link><pubDate>Sun, 01 Oct 2023 23:30:46 +0800</pubDate><guid>https://michaelmao.me/blog/building-blocks-of-neural-networks/</guid><description>convolution operation on a padded 2D array
Purpose This series goes over the basic building blocks of Neural Networks, following the API provided by PyTorch.
The PyTorch documentation provides good explanation of the API, the calculation made, and the shapes of the inputs, outputs, and weights. However, dense text descriptions and mathematical formulas aren&amp;rsquo;t necessarily intuitive. This series aims to provide intuition at a glance to serve as a reference/memo that supplements the PyTorch documentation.</description></item></channel></rss>